{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13044152,"sourceType":"datasetVersion","datasetId":8259797}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"11292d40-541d-4f23-9946-1d46cd35c85d","cell_type":"code","source":"!rm -rf diffusionAD","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"9fcf9b99-af80-4052-a1ed-1e9d4e59c671","cell_type":"code","source":"!git clone https://github.com/nguyenduchuyiu/diffusionAD.git","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e3df76b4-1322-4f59-801c-5d8bef7e4e48","cell_type":"code","source":"%cd diffusionAD\n!git checkout c9c39c9e4e96a65b06ad1e0c4509aeb0bfc4bc4f","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7dc6ccda-4df0-46a8-b05d-b29cfd5ba7e4","cell_type":"code","source":"%%writefile args/args1.json\n\n{\n  \"img_size\": [512,512],\n  \"Batch_Size\": 8,\n  \"EPOCHS\": 3000,\n  \"T\": 1000,\n  \"base_channels\": 128,\n  \"beta_schedule\": \"linear\",\n  \"loss_type\": \"l2\",\n  \"diffusion_lr\": 1e-4,\n  \"seg_lr\": 1e-5,\n  \"random_slice\": true,\n  \"weight_decay\": 0.0,\n  \"save_imgs\":true,\n  \"save_vids\":false, \n  \"dropout\":0,\n  \"attention_resolutions\":\"32,16,8\",\n  \"num_heads\":4,\n  \"num_head_channels\":-1,\n  \"noise_fn\":\"gauss\",\n  \"channels\":3,\n  \"data_name\":\"RealIAD\",\n  \"data_root_path\":\"/kaggle/input/pcb-dataset\",\n  \"anomaly_source_path\":\"/kaggle/input/pcb-dataset/dtd\",\n  \"noisier_t_range\":600,\n  \"less_t_range\":300,\n  \"condition_w\":1,\n  \"eval_normal_t\":200,\n  \"eval_noisier_t\":400,\n  \"output_path\":\"outputs\",\n  \"gradient_accumulation_steps\": 2,\n  \"use_mixed_precision\": true,\n  \"channel_mults\": [1, 1, 1, 2, 2, 4, 4],\n  \"loss_weight\": \"uniform\",\n  \"loss-type\": \"l2\",\n  \"resume_training\": true,\n  \"use_gradient_checkpointing\": true,\n  \"use_bfloat16\": true\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f29c1ded-63c8-4a70-9804-5c906bf64d03","cell_type":"code","source":"!python3 -u src/train.py","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"5ef4c18d-410e-4ef6-ae53-bce8afba3326","cell_type":"code","source":"import torch, gc\n\ngc.collect() \ntorch.cuda.empty_cache()  \ntorch.cuda.ipc_collect()  \nfrom eval import testing, load_parameters, defaultdict_from_json\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Check for multiple GPUs\nnum_gpus = torch.cuda.device_count()\nprint(f\"Number of available GPUs: {num_gpus}\")\nif num_gpus > 1:\n    print(f\"Using {num_gpus} GPUs for evaluation\")\nelif num_gpus == 1:\n    print(\"Using single GPU for evaluation\")\nelse:\n    print(\"Using CPU for evaluation\")\nfile = \"args1.json\"\n# load the json args\nwith open(f'./args/{file}', 'r') as f:\n    args = json.load(f)\nargs['arg_num'] = file[4:-5]\nargs = defaultdict_from_json(args)\nreal_iad_classes = os.listdir(os.path.join(args[\"data_root_path\"], args['data_name']))\n\ncurrent_classes = real_iad_classes\ncheckpoint_types = ['best', 'last']\n\nfor sub_class in current_classes:\n    for checkpoint_type in checkpoint_types:\n        try:\n            args, output = load_parameters(device, sub_class, checkpoint_type)\n        except FileNotFoundError:\n            print(f\"Checkpoint {checkpoint_type} not found for class {sub_class}, skipping.\")\n            continue\n\n        print(f\"args{args['arg_num']}\")\n        print(\"class\", sub_class)\n        \n        in_channels = args[\"channels\"]\n\n        unet_model = UNetModel(args['img_size'][0], args['base_channels'], channel_mults=args['channel_mults'], dropout=args[\n                    \"dropout\"], n_heads=args[\"num_heads\"], n_head_channels=args[\"num_head_channels\"],\n                in_channels=in_channels\n                ).to(device)\n\n        seg_model = SegmentationSubNetwork(in_channels=6, out_channels=1).to(device)\n\n        # Load model states\n        unet_model.load_state_dict(output[\"unet_model_state_dict\"])\n        unet_model.to(device)\n        \n        seg_model.load_state_dict(output[\"seg_model_state_dict\"])\n        seg_model.to(device)\n        \n        # Enable multi-GPU for evaluation if available\n        if num_gpus > 1:\n            print(f\"Wrapping models with DataParallel for {num_gpus} GPUs\")\n            unet_model = torch.nn.DataParallel(unet_model)\n            seg_model = torch.nn.DataParallel(seg_model)\n        \n        unet_model.eval()\n        seg_model.eval()\n\n        print(\"EPOCH:\", output['n_epoch'])\n\n        testing_dataset = RealIADTestDataset(\n            args[\"data_root_path\"], sub_class, img_size=args[\"img_size\"]\n        )\n        class_type = args['data_name']\n                \n        data_len = len(testing_dataset) \n        test_loader = DataLoader(testing_dataset, batch_size=1, shuffle=False, num_workers=4)\n\n        # make arg specific directories\n        for i in [f'{args[\"output_path\"]}/metrics/ARGS={args[\"arg_num\"]}/{sub_class}']:\n            try:\n                os.makedirs(i)\n            except OSError:\n                pass\n\n        testing(test_loader, args, unet_model, seg_model, data_len, sub_class, class_type, checkpoint_type, device)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4464b774-6925-4fd6-9fa7-abd402a52df1","cell_type":"code","source":"import sys\n!{sys.executable} -m pip install matplotlib","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}