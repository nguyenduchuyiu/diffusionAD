{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11292d40-541d-4f23-9946-1d46cd35c85d",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!rm -rf diffusionAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcf9b99-af80-4052-a1ed-1e9d4e59c671",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/nguyenduchuyiu/diffusionAD.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3df76b4-1322-4f59-801c-5d8bef7e4e48",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%cd diffusionAD\n",
    "!git checkout c9c39c9e4e96a65b06ad1e0c4509aeb0bfc4bc4f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc6ccda-4df0-46a8-b05d-b29cfd5ba7e4",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%writefile args/args1.json\n",
    "\n",
    "{\n",
    "  \"img_size\": [512,512],\n",
    "  \"Batch_Size\": 8,\n",
    "  \"EPOCHS\": 3000,\n",
    "  \"T\": 1000,\n",
    "  \"base_channels\": 128,\n",
    "  \"beta_schedule\": \"linear\",\n",
    "  \"loss_type\": \"l2\",\n",
    "  \"diffusion_lr\": 1e-4,\n",
    "  \"seg_lr\": 1e-5,\n",
    "  \"random_slice\": true,\n",
    "  \"weight_decay\": 0.0,\n",
    "  \"save_imgs\":true,\n",
    "  \"save_vids\":false, \n",
    "  \"dropout\":0,\n",
    "  \"attention_resolutions\":\"32,16,8\",\n",
    "  \"num_heads\":4,\n",
    "  \"num_head_channels\":-1,\n",
    "  \"noise_fn\":\"gauss\",\n",
    "  \"channels\":3,\n",
    "  \"data_name\":\"RealIAD\",\n",
    "  \"data_root_path\":\"/kaggle/input/pcb-dataset\",\n",
    "  \"anomaly_source_path\":\"/kaggle/input/pcb-dataset/dtd\",\n",
    "  \"noisier_t_range\":600,\n",
    "  \"less_t_range\":300,\n",
    "  \"condition_w\":1,\n",
    "  \"eval_normal_t\":200,\n",
    "  \"eval_noisier_t\":400,\n",
    "  \"output_path\":\"outputs\",\n",
    "  \"gradient_accumulation_steps\": 2,\n",
    "  \"use_mixed_precision\": true,\n",
    "  \"channel_mults\": [1, 1, 1, 2, 2, 4, 4],\n",
    "  \"loss_weight\": \"uniform\",\n",
    "  \"loss-type\": \"l2\",\n",
    "  \"resume_training\": true,\n",
    "  \"use_gradient_checkpointing\": true,\n",
    "  \"use_bfloat16\": false\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c1ded-63c8-4a70-9804-5c906bf64d03",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!python3 -u src/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef4c18d-410e-4ef6-ae53-bce8afba3326",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "\n",
    "gc.collect() \n",
    "torch.cuda.empty_cache()  \n",
    "torch.cuda.ipc_collect()  \n",
    "from eval import testing, load_parameters, defaultdict_from_json\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check for multiple GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of available GPUs: {num_gpus}\")\n",
    "if num_gpus > 1:\n",
    "    print(f\"Using {num_gpus} GPUs for evaluation\")\n",
    "elif num_gpus == 1:\n",
    "    print(\"Using single GPU for evaluation\")\n",
    "else:\n",
    "    print(\"Using CPU for evaluation\")\n",
    "file = \"args1.json\"\n",
    "# load the json args\n",
    "with open(f'./args/{file}', 'r') as f:\n",
    "    args = json.load(f)\n",
    "args['arg_num'] = file[4:-5]\n",
    "args = defaultdict_from_json(args)\n",
    "real_iad_classes = os.listdir(os.path.join(args[\"data_root_path\"], args['data_name']))\n",
    "\n",
    "current_classes = real_iad_classes\n",
    "checkpoint_types = ['best', 'last']\n",
    "\n",
    "for sub_class in current_classes:\n",
    "    for checkpoint_type in checkpoint_types:\n",
    "        try:\n",
    "            args, output = load_parameters(device, sub_class, checkpoint_type)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Checkpoint {checkpoint_type} not found for class {sub_class}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"args{args['arg_num']}\")\n",
    "        print(\"class\", sub_class)\n",
    "        \n",
    "        in_channels = args[\"channels\"]\n",
    "\n",
    "        unet_model = UNetModel(args['img_size'][0], args['base_channels'], channel_mults=args['channel_mults'], dropout=args[\n",
    "                    \"dropout\"], n_heads=args[\"num_heads\"], n_head_channels=args[\"num_head_channels\"],\n",
    "                in_channels=in_channels\n",
    "                ).to(device)\n",
    "\n",
    "        seg_model = SegmentationSubNetwork(in_channels=6, out_channels=1).to(device)\n",
    "\n",
    "        # Load model states\n",
    "        unet_model.load_state_dict(output[\"unet_model_state_dict\"])\n",
    "        unet_model.to(device)\n",
    "        \n",
    "        seg_model.load_state_dict(output[\"seg_model_state_dict\"])\n",
    "        seg_model.to(device)\n",
    "        \n",
    "        # Enable multi-GPU for evaluation if available\n",
    "        if num_gpus > 1:\n",
    "            print(f\"Wrapping models with DataParallel for {num_gpus} GPUs\")\n",
    "            unet_model = torch.nn.DataParallel(unet_model)\n",
    "            seg_model = torch.nn.DataParallel(seg_model)\n",
    "        \n",
    "        unet_model.eval()\n",
    "        seg_model.eval()\n",
    "\n",
    "        print(\"EPOCH:\", output['n_epoch'])\n",
    "\n",
    "        testing_dataset = RealIADTestDataset(\n",
    "            args[\"data_root_path\"], sub_class, img_size=args[\"img_size\"]\n",
    "        )\n",
    "        class_type = args['data_name']\n",
    "                \n",
    "        data_len = len(testing_dataset) \n",
    "        test_loader = DataLoader(testing_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "        # make arg specific directories\n",
    "        for i in [f'{args[\"output_path\"]}/metrics/ARGS={args[\"arg_num\"]}/{sub_class}']:\n",
    "            try:\n",
    "                os.makedirs(i)\n",
    "            except OSError:\n",
    "                pass\n",
    "\n",
    "        testing(test_loader, args, unet_model, seg_model, data_len, sub_class, class_type, checkpoint_type, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4464b774-6925-4fd6-9fa7-abd402a52df1",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install matplotlib"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8259797,
     "sourceId": 13044152,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
